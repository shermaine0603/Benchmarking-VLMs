## Benchmarking-VLMs

# Purpose
Purpose of this project is to benchmark various VLMs (Vision Language Models) to determine the best for use.
For this project, Ollama was used to run the models inside a Docker Container.

# Prerequisites
 - Ubuntu 22.04
 - Cuda 12.6
 - Docker is installed
To install Docker, visit [here](https://docs.docker.com/engine/install/ubuntu/)




